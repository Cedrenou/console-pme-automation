# üîç D√©bogage : ZIP vide apr√®s t√©l√©chargement

Si le t√©l√©chargement semble r√©ussir mais que le ZIP est vide, voici comment identifier et r√©soudre le probl√®me.

---

## üéØ Causes possibles

1. **Le prefix S3 ne correspond pas au batchId** (le plus fr√©quent)
2. **La lambda ne trouve pas de fichiers dans S3**
3. **Probl√®me d'encodage base64**
4. **La lambda retourne une erreur mais le front-end ne l'affiche pas**
5. **Le format de r√©ponse de la lambda n'est pas correct pour API Gateway**

---

## üîß Diagnostic √©tape par √©tape

### √âtape 1 : V√©rifier les logs CloudWatch de la Lambda

1. **Aller dans AWS Console** ‚Üí **Lambda** ‚Üí S√©lectionner `downloadImageBatch`
2. **Onglet "Surveiller"** ‚Üí Cliquer sur **"Voir les logs dans CloudWatch"**
3. **Ouvrir le dernier log** et v√©rifier :
   - Le `batchId` re√ßu
   - Le `prefix` calcul√©
   - Le nombre de fichiers trouv√©s dans `response['Contents']`
   - Les erreurs √©ventuelles

**Ce qu'on cherche** :
```python
# Si vous voyez √ßa, c'est bon :
print(f"Batch ID re√ßu: {batch_id}")
print(f"Prefix calcul√©: {prefix}")
print(f"Nombre de fichiers trouv√©s: {len(response.get('Contents', []))}")

# Si vous voyez √ßa, c'est mauvais :
# "Nombre de fichiers trouv√©s: 0"  ‚Üê Probl√®me de prefix
# "Batch not found"  ‚Üê Le prefix ne correspond pas
```

---

### √âtape 2 : V√©rifier le format du batchId vs le prefix S3

**Le probl√®me le plus fr√©quent** : La conversion `batchId.replace('-', '/')` ne correspond pas au vrai chemin S3.

#### A. Trouver le vrai prefix S3

1. **Aller dans S3** ‚Üí Votre bucket
2. **Naviguer jusqu'au dossier** que vous voulez t√©l√©charger
3. **Copier le chemin complet** (ex: `renouvellement-annonce-vinted/output/annonces/renouv-test/`)

#### B. V√©rifier le batchId affich√© dans l'interface

Dans votre interface, quel est le `batchId` affich√© ? (ex: `renouv-test`)

#### C. Comparer avec la conversion de la Lambda

La lambda fait :
```python
prefix = batch_id.replace('-', '/') + '/'
# Si batchId = "renouv-test" ‚Üí prefix = "renouv/test/"
```

**Si le vrai prefix S3 est** `renouvellement-annonce-vinted/output/annonces/renouv-test/`  
**Mais le batchId est** `renouv-test`  
**Alors la conversion donne** `renouv/test/` ‚ùå

**‚Üí Les chemins ne correspondent pas !**

---

### √âtape 3 : V√©rifier la r√©ponse HTTP dans le navigateur

Ajoutez des logs temporaires dans le code front-end pour voir ce qui est re√ßu :

**Modifier `src/lib/api.ts`** :

```typescript
export async function downloadImageBatch(batchId: string): Promise<Blob> {
  console.log("downloadImageBatch pour lot:", batchId);
  
  const res = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/s3/download-images-batch/${batchId}`);
  
  // ‚ö†Ô∏è AJOUTER CES LOGS
  console.log("Status HTTP:", res.status);
  console.log("Content-Type:", res.headers.get('Content-Type'));
  console.log("Content-Length:", res.headers.get('Content-Length'));
  
  if (!res.ok) {
    const errorText = await res.text();
    console.error("Erreur API:", errorText);
    throw new Error(`Erreur ${res.status}: ${errorText}`);
  }
  
  const blob = await res.blob();
  console.log("Taille du blob re√ßu:", blob.size, "bytes");
  
  // V√©rifier si le blob est vraiment vide
  if (blob.size === 0) {
    console.error("‚ö†Ô∏è Le blob est vide ! Probl√®me c√¥t√© Lambda ou API Gateway");
  }
  
  return blob;
}
```

**Apr√®s avoir ajout√© ces logs** :
1. Ouvrir la console du navigateur (F12)
2. Cliquer sur "T√©l√©charger"
3. Regarder les logs

**Interpr√©tation** :
- `Content-Length: 0` ‚Üí La lambda ne retourne rien ou retourne un ZIP vide
- `Status HTTP: 200` mais `blob.size: 0` ‚Üí La lambda retourne une r√©ponse vide
- `Status HTTP: 500` ‚Üí Erreur dans la lambda (voir logs CloudWatch)

---

### √âtape 4 : Tester directement l'endpoint API Gateway

Tester avec `curl` pour voir la r√©ponse brute :

```bash
curl -v https://[votre-api-id].execute-api.[region].amazonaws.com/[stage]/s3/download-images-batch/[batchId] -o test.zip
```

**Regarder** :
- Le `Content-Length` dans les headers
- Le code HTTP (200, 404, 500, etc.)
- La taille du fichier t√©l√©charg√© : `ls -lh test.zip`

**Si `test.zip` est vide ou fait 0 bytes** ‚Üí Le probl√®me est dans la Lambda ou l'API Gateway.

**Si `test.zip` contient des donn√©es** ‚Üí Le probl√®me est dans le front-end (peu probable).

---

## üõ†Ô∏è Solutions selon le probl√®me

### Solution 1 : Corriger la conversion batchId ‚Üí prefix

Si le `batchId` ne contient pas le chemin complet, vous avez 2 options :

#### Option A : Modifier la lambda pour utiliser le prefix complet

Au lieu de convertir le batchId, r√©cup√©rez le prefix directement depuis la liste des batches :

**Modifier la lambda** :
```python
import boto3
import io
import zipfile
import json
import base64

def handler(event, context):
    s3 = boto3.client('s3')
    bucket_name = 'votre-bucket-annonces'  # ‚ö†Ô∏è √Ä MODIFIER
    
    batch_id = event.get('pathParameters', {}).get('batchId', '')
    
    # ‚ö†Ô∏è SOLUTION : Utiliser directement le batchId comme prefix
    # Si votre batchId est d√©j√† le prefix complet depuis S3
    # Exemple : batchId = "renouvellement-annonce-vinted/output/annonces/renouv-test"
    
    # Si batchId contient des tirets qu'il faut convertir
    # Testez les deux m√©thodes :
    
    # M√©thode 1 : Si batchId est d√©j√† un prefix
    prefix = batch_id if batch_id.endswith('/') else batch_id + '/'
    
    # OU M√©thode 2 : Si batchId utilise des tirets comme s√©parateurs
    # prefix = batch_id.replace('-', '/') + '/'
    
    # OU M√©thode 3 : Si vous passez le prefix complet dans le batchId
    # prefix = batch_id  # Utiliser directement
    
    print(f"Batch ID re√ßu: {batch_id}")
    print(f"Prefix utilis√©: {prefix}")
    
    # R√©cup√©rer tous les objets du pr√©fixe
    response = s3.list_objects_v2(
        Bucket=bucket_name,
        Prefix=prefix
    )
    
    print(f"Nombre d'objets trouv√©s: {len(response.get('Contents', []))}")
    
    if 'Contents' not in response or len(response['Contents']) == 0:
        return {
            'statusCode': 404,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'error': 'Batch not found or empty',
                'batchId': batch_id,
                'prefix': prefix,
                'found_objects': 0
            })
        }
    
    # Cr√©er un ZIP en m√©moire
    zip_buffer = io.BytesIO()
    files_added = 0
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for obj in response['Contents']:
            try:
                # T√©l√©charger l'objet depuis S3
                s3_obj = s3.get_object(Bucket=bucket_name, Key=obj['Key'])
                content = s3_obj['Body'].read()
                
                # Ajouter au ZIP avec le nom de fichier uniquement
                file_name = obj['Key'].split('/')[-1]
                if file_name:  # Ignorer les objets qui sont des dossiers
                    zip_file.writestr(file_name, content)
                    files_added += 1
                    print(f"Ajout√© au ZIP: {file_name} ({len(content)} bytes)")
            except Exception as e:
                print(f"Erreur lors du traitement de {obj['Key']}: {str(e)}")
                continue
    
    print(f"Total fichiers ajout√©s au ZIP: {files_added}")
    
    if files_added == 0:
        return {
            'statusCode': 404,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'error': 'No files to zip',
                'batchId': batch_id,
                'prefix': prefix
            })
        }
    
    zip_buffer.seek(0)
    zip_size = len(zip_buffer.getvalue())
    print(f"Taille du ZIP cr√©√©: {zip_size} bytes")
    
    # Encoder en base64 pour l'API Gateway
    zip_base64 = base64.b64encode(zip_buffer.getvalue()).decode('utf-8')
    
    return {
        'statusCode': 200,
        'headers': {
            'Content-Type': 'application/zip',
            'Content-Disposition': f'attachment; filename="{batch_id}.zip"',
            'Access-Control-Allow-Origin': '*'
        },
        'body': zip_base64,
        'isBase64Encoded': True
    }
```

#### Option B : Modifier le front-end pour passer le prefix complet

Si votre `ImageBatch` contient d√©j√† le `prefix`, utilisez-le directement :

**Modifier `src/app/renouvellement-annonces/page.tsx`** :

```typescript
const handleDownload = async (batch: ImageBatch) => {
  setDownloadingBatch(batch.batchId);
  try {
    // Utiliser le prefix au lieu du batchId si disponible
    const identifier = batch.prefix || batch.batchId;
    const blob = await downloadImageBatch(identifier);
    // ... reste du code
  }
}
```

---

### Solution 2 : V√©rifier que la lambda traite correctement la r√©ponse API Gateway

Si vous utilisez **Lambda Proxy Integration** (recommand√©), la lambda re√ßoit l'√©v√©nement directement d'API Gateway.

**V√©rifier dans API Gateway** :
1. S√©lectionner la m√©thode GET
2. Onglet "Int√©gration"
3. V√©rifier que **"Utiliser le proxy Lambda"** est activ√© ‚úÖ

Si ce n'est pas le cas, l'√©v√©nement peut √™tre dans un format diff√©rent.

---

### Solution 3 : V√©rifier l'encodage base64

Si la lambda retourne `isBase64Encoded: True`, le body doit √™tre en base64.

**Ajouter des logs dans la lambda** :
```python
zip_base64 = base64.b64encode(zip_buffer.getvalue()).decode('utf-8')
print(f"Taille ZIP original: {len(zip_buffer.getvalue())} bytes")
print(f"Taille base64: {len(zip_base64)} caract√®res")
print(f"Premiers caract√®res base64: {zip_base64[:50]}...")

return {
    'statusCode': 200,
    'headers': { ... },
    'body': zip_base64,
    'isBase64Encoded': True  # ‚ö†Ô∏è IMPORTANT : Doit √™tre True
}
```

---

## üìã Checklist de v√©rification

- [ ] V√©rifier les logs CloudWatch de la Lambda
- [ ] Comparer le `batchId` avec le vrai prefix S3
- [ ] Ajouter des logs dans le front-end pour voir la taille du blob
- [ ] Tester avec `curl` directement l'endpoint API Gateway
- [ ] V√©rifier que la lambda trouve bien des fichiers (`len(response['Contents']) > 0`)
- [ ] V√©rifier que des fichiers sont ajout√©s au ZIP (`files_added > 0`)
- [ ] V√©rifier que `isBase64Encoded: True` est pr√©sent dans la r√©ponse
- [ ] V√©rifier que le Content-Type est `application/zip`

---

## üéØ Solution rapide : Lambda avec logs d√©taill√©s

Voici une version de la lambda avec tous les logs n√©cessaires pour d√©boguer :

```python
import boto3
import io
import zipfile
import json
import base64

def handler(event, context):
    s3 = boto3.client('s3')
    bucket_name = 'sunset-s3'  # ‚ö†Ô∏è √Ä MODIFIER selon votre bucket
    
    # R√©cup√©rer le batchId depuis les pathParameters
    batch_id = event.get('pathParameters', {}).get('batchId', '')
    
    print(f"üîç DEBUG - Batch ID re√ßu: {batch_id}")
    print(f"üîç DEBUG - Event complet: {json.dumps(event)}")
    
    # Essayer diff√©rentes m√©thodes de conversion
    # Selon votre structure S3, ajustez cette partie
    if '/' in batch_id:
        # Le batchId contient d√©j√† des slashes (prefix complet)
        prefix = batch_id if batch_id.endswith('/') else batch_id + '/'
    else:
        # Le batchId utilise des tirets, les convertir
        prefix = batch_id.replace('-', '/') + '/'
    
    print(f"üîç DEBUG - Prefix calcul√©: {prefix}")
    print(f"üîç DEBUG - Bucket: {bucket_name}")
    
    # R√©cup√©rer tous les objets du pr√©fixe
    try:
        response = s3.list_objects_v2(
            Bucket=bucket_name,
            Prefix=prefix
        )
        
        contents = response.get('Contents', [])
        print(f"üîç DEBUG - Nombre d'objets trouv√©s: {len(contents)}")
        
        if len(contents) == 0:
            print(f"‚ùå ERREUR - Aucun objet trouv√© pour le prefix: {prefix}")
            return {
                'statusCode': 404,
                'headers': {
                    'Content-Type': 'application/json',
                    'Access-Control-Allow-Origin': '*'
                },
                'body': json.dumps({
                    'error': 'No files found',
                    'batchId': batch_id,
                    'prefix': prefix,
                    'bucket': bucket_name
                })
            }
        
        # Afficher les premiers objets trouv√©s
        print(f"üîç DEBUG - Premiers objets trouv√©s:")
        for i, obj in enumerate(contents[:5]):
            print(f"  {i+1}. {obj['Key']} ({obj.get('Size', 0)} bytes)")
        
    except Exception as e:
        print(f"‚ùå ERREUR lors de list_objects_v2: {str(e)}")
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({'error': str(e)})
        }
    
    # Cr√©er un ZIP en m√©moire
    zip_buffer = io.BytesIO()
    files_added = 0
    total_size = 0
    
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for obj in contents:
            try:
                key = obj['Key']
                print(f"üì¶ Traitement: {key}")
                
                # T√©l√©charger l'objet depuis S3
                s3_obj = s3.get_object(Bucket=bucket_name, Key=key)
                content = s3_obj['Body'].read()
                
                # Ajouter au ZIP avec le nom de fichier uniquement
                file_name = key.split('/')[-1]
                if file_name:  # Ignorer les objets qui sont des dossiers
                    zip_file.writestr(file_name, content)
                    files_added += 1
                    total_size += len(content)
                    print(f"‚úÖ Ajout√©: {file_name} ({len(content)} bytes)")
            except Exception as e:
                print(f"‚ùå Erreur pour {obj['Key']}: {str(e)}")
                continue
    
    print(f"üîç DEBUG - Fichiers ajout√©s au ZIP: {files_added}")
    print(f"üîç DEBUG - Taille totale des fichiers: {total_size} bytes")
    
    if files_added == 0:
        print(f"‚ùå ERREUR - Aucun fichier ajout√© au ZIP")
        return {
            'statusCode': 404,
            'headers': {
                'Content-Type': 'application/json',
                'Access-Control-Allow-Origin': '*'
            },
            'body': json.dumps({
                'error': 'No files added to zip',
                'batchId': batch_id,
                'prefix': prefix,
                'objects_found': len(contents)
            })
        }
    
    zip_buffer.seek(0)
    zip_bytes = zip_buffer.getvalue()
    zip_size = len(zip_bytes)
    print(f"üîç DEBUG - Taille du ZIP cr√©√©: {zip_size} bytes")
    
    # Encoder en base64 pour l'API Gateway
    zip_base64 = base64.b64encode(zip_bytes).decode('utf-8')
    print(f"üîç DEBUG - Taille base64: {len(zip_base64)} caract√®res")
    
    return {
        'statusCode': 200,
        'headers': {
            'Content-Type': 'application/zip',
            'Content-Disposition': f'attachment; filename="{batch_id}.zip"',
            'Access-Control-Allow-Origin': '*'
        },
        'body': zip_base64,
        'isBase64Encoded': True
    }
```

Cette version avec logs vous dira exactement o√π est le probl√®me !

---

## üöÄ Prochaines √©tapes

1. **D√©ployer cette version de la lambda** avec tous les logs
2. **Tester le t√©l√©chargement**
3. **Regarder les logs CloudWatch**
4. **Identifier le probl√®me** (prefix incorrect, aucun fichier trouv√©, etc.)
5. **Corriger selon la solution correspondante**

